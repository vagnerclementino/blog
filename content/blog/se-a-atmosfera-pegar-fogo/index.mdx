---
title: "E se a atmosfera tivesse pegado fogo..."
date: "2023-12-10"
description: "Discussões sobre os limites étnicos do uso de IA"
featuredImage: frankenstein.webp
---

## O dia do julgamento

A cultura pop nos trouxe diferentes histórias de um evolução tecnlogica em que
as máquinas se tornam concientes e vejam a huminadade como uma ameaça. Esse é o
enredo da série _Exterminador do Futuro (Terminator)_ que nos apresenta a
[Skynet](https://terminator.fandom.com/wiki/Skynet), uma inteligência artificial
criada pela Cyberdyne Systems e que decidiu que todos os seres humanos como uma
ameaça.

![Logo da Skynet, o sistema de IA que iniciou o Dia do Julgamento](./Skynet_logo.webp)

Após perceberem os riscos da Skinet, os cientistas decidiram desligá-la. Como
forma de relatiação ou defesa, o sistema autônomo disparou mísseis nucleares
americanos contra alvos na Rússia. A Rússia revidou, iniciando assim um
holocausto nuclear conhecido como o _Dia do Julgamento_. 

A estória descrita anteriormente é uma sintese de vários enredos de um momento
histórico conhecido como Guerra Fria. Falando sobre o século XX, voltemos um
pouco no tempo, para um momento antes da corrida nuclear da Guerra Fria.

## O ínicio do fim

Em 2023 foi lançada a filme-biografia de [J. Robert
Oppenheimer](https://blogs.pucpr.br/eeh/2023/08/29/oppenheimer-pai-da-bomba-atomica-e-dos-buracos-negros/)
que foi físico nuclear que liderou o [Projeto
Manhattan](https://en.wikipedia.org/wiki/Manhattan_Project). O objetvo do
projecto era dominar a tecnologia de construção de uma arma nuclear antes dos
alemães. **Para aqueles que não tenham assistido ao filme, o próximo paragrafo
pode conter um _spoiler_**.

Em 1942, Edward Teller, um dos pesquisadores que participava do Projeto
Manhattan, fez uma apresentação na qual observou que uma explosão atômica
poderia criar as condições sob as quais as reações de fusão poderiam ocorrer. Em
teoria, haveria uma chance remota de uma bomba atomica inicia-se uma igninição
de toda a atmosfera[^1].

Na época, dado o pouco conhecimento sobre a fissão nuclear, a teoria apenas
poderia ser totalmente descartada com um teste real. Apesar do risco, a
justificativa ética em prosseguir com o projeto era evitar que os nazistas
tivesse a bomba antes. É importante dizer que em julho de 1945, época do
fatídico teste Trinity, a Alemanha nazista já havia se rendido.

![Detonação da bomba atomica no teste Trinity](./TrinityDetonation1945GIF.gif)

Nesse momento, meu caro leitor, precisamos nos fazer a seguinte pergunta: **Qual
é o limite (étnico) para o teste/evolução de uma nova técnologia?**

Trazendo para o tema central desse texto, _qual deveria ser a nossa atitude se
próxima geração de ferramentas de IA, pudesse incendiar o nosso mundo_?!

## Ferramentas de IA não são mais o futuro

O ano de 2023 pode ser considerado como um ponto de inflexão no uso das IAs
generativas. Pelo menos em alguns nichos, como o desenvolvimento de software.
Soluções como [Github Copilot](https://github.com/features/copilot), [AWS Code
Whisperer](https://aws.amazon.com/pt/codewhisperer/) e [AI Assistant da
JetBrains](https://blog.jetbrains.com/idea/2023/06/ai-assistant-in-jetbrains-ides/)
já fazem parte do ecossitemas de muitos desenvolvedores, com o objetivo de
acelerar a codificação, reduzir tarefas repetitivas e ajudar na escrita de
testes.

Menos com certa desconfiança de alguns (inclusive eu), o uso de ferramentas de
inteligência articial me parece um caminho sem volta. Todavia, a discussão sobre
os parâmetros éticos que governam esse tipo de ferramenta preciam ser
discutidos. Vamos a alguns exemplos recentes.

### Frankenstein e a AI Generativa

O [Prêmio Jabuti](https://www.premiojabuti.com.br/) é o mais tradicional prêmio
literário do Brasil, concedido pela Câmara Brasileira do Livro (CBL). A
ilustração do clássico _Frankenstein_ de Mary Shelley foi desclassificado por
ter utilizado o suporte de ferramentas de IA. A justificat foi que _“as regras
da premiação estabelecem que casos não previstos no regulamento sejam
deliberados pela curadoria, e a avaliação de obras que utilizam IA em sua
produção não estava contemplada nessas regras”_[^2]. Coincidência ou não, chega
ser irônico que essa discussão tenha ocorrido na cada de um livro cujo ponto
central seja a relação entre criador e criatura.

Em vagas de tecnologia é possível "levar uma tarefa para casa" como uma das
etapas do processo seletivo. No papel de avaliador, deveríamos considerar
válidas soluções que utilizem algum suporte de IA? Seria possível separar a
contribuição da "máquina" em determinada solução proposta pelo candidato? 

Se definir os limites de propriedade intelectual está cada vez mais complexo,
imagine quando o uso da inteligência articial pode definir entre vida e morte.

### O Evangelho: massificando ataques a bomba com IA

O jornal _The Guardian_ relevou a existência de um sistema isralense chamado de
_The Gospel_ (O Evangelho). Trata-se de um sistema orientado a dados
(_data-driven_) que utliza IA para definir alvos em Gaza que minizem o número de
vítimas civis[^3]. No contexto de uma guerra, uma visão tecnocráta poderia
encontrar valor na definição de um processo técnico e não enviesado para
definição de alvos de guerra. Em 2021, as autoridades de Israel revelaram que
haviam travado sua "primeira guerra de IA" usando _machine learning_ e
computação avançada.

Para aqueles que conhecem um pouco sobre o desenho de sistemas de inteligência
artificial sabe que é pouco provavél construí-los sem algum tipo de viés. Nesse
sentido, um sistema que define alvo militares, necessita ser configurado com
parâmetros que traz em si todo enviesamento intríseco a qualquer humano. O fato
de um sistema de software fazer parte do fluxo de decisão de quem vive ou quem
morre é assustador.  Existe o perigo de consideramos tais sistemas de tomada de
decisão como neutros e percamos a capacidade de termos uma visão críticas sobre
os resultados.

## 

Considerando a tecnologia atual, se sistemas como a _Skynet_ ainda são obras de
ficção, exemplos como o _The Gospel_ demostra a importância de discutimos a
abragências dos sistemas que utilizam IA, especialmente em tomadas de decisão.
Se partirmos da premissa que os resultados fornecidos por esse tipo de
ferramenta como uma verdade absoluta e neutra, podemos nos tornar mera
engregagens em decisões humanas complexas. Pode ser que dessa vez a atmosfera
vai incendiar.

[^1]:
    Na vida real, equipe de Oppenheimer temia destruir mundo com 1ª bomba atômica.
    https://gizmodo.uol.com.br/na-vida-real-equipe-de-oppenheimer-temia-destruir-mundo-com-1a-bomba-atomica.

[^2]:
    Livro ilustrado por IA é retirado da lista do Prêmio Jabuti.
    https://agenciabrasil.ebc.com.br/geral/noticia/2023-11/livro-ilustrado-por-ia-e-retirado-da-lista-do-premio-jabuti
[^3]:
    'The Gospel': how Israel uses AI to select bombing targets in Gaza.
    https://www.theguardian.com/world/2023/dec/01/the-gospel-how-israel-uses-ai-to-select-bombing-targets